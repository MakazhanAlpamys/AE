# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å –∏–º–ø–æ—Ä—Ç–∞ CSV/XLSX —Ñ–∞–π–ª–æ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
"""

import pandas as pd
import os
from datetime import datetime
from typing import Dict, List, Tuple
import io


class ImportValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ"""
    
    REQUIRED_COLUMNS = {
        'objects': ['object_id', 'object_name', 'object_type', 'pipeline_id', 'lat', 'lon'],
        'diagnostics': ['diag_id', 'object_id', 'method', 'date', 'defect_found']
    }
    
    VALID_OBJECT_TYPES = ['crane', 'compressor', 'pipeline_section']
    VALID_METHODS = ['VIK', 'UZK', 'MFL', 'TFI', 'GEO', 'MPK', 'PVK', 'RGK', 'TVK', 'VIBRO', 'UTWM', 'AE', 'TOFD']
    VALID_QUALITY_GRADES = ['—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ', '–¥–æ–ø—É—Å—Ç–∏–º–æ', '—Ç—Ä–µ–±—É–µ—Ç_–º–µ—Ä', '–Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–æ']
    VALID_ML_LABELS = ['normal', 'medium', 'high']
    
    def __init__(self):
        self.errors = []
        self.warnings = []
    
    def validate_objects(self, df: pd.DataFrame) -> Tuple[bool, List[str], List[str]]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã –æ–±—ä–µ–∫—Ç–æ–≤"""
        self.errors = []
        self.warnings = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        missing_cols = set(self.REQUIRED_COLUMNS['objects']) - set(df.columns)
        if missing_cols:
            found_cols = ', '.join(df.columns.tolist())
            self.errors.append(
                f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_cols)}\n"
                f"üìã –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ñ–∞–π–ª–µ: {found_cols}\n"
                f"üí° –°–∫–∞—á–∞–π—Ç–µ —à–∞–±–ª–æ–Ω –∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ (—Ä–µ–≥–∏—Å—Ç—Ä –≤–∞–∂–µ–Ω!)"
            )
            return False, self.errors, self.warnings
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ object_id
        if df['object_id'].duplicated().any():
            duplicates = df[df['object_id'].duplicated()]['object_id'].tolist()
            self.errors.append(f"–î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è object_id: {duplicates[:5]}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤
        invalid_types = df[~df['object_type'].isin(self.VALID_OBJECT_TYPES)]['object_type'].unique()
        if len(invalid_types) > 0:
            self.warnings.append(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–∏–ø—ã –æ–±—ä–µ–∫—Ç–æ–≤: {list(invalid_types)}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
        if ((df['lat'] < -90) | (df['lat'] > 90)).any():
            self.errors.append("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —à–∏—Ä–æ—Ç—ã (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Ç -90 –¥–æ 90)")
        
        if ((df['lon'] < -180) | (df['lon'] > 180)).any():
            self.errors.append("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–ª–≥–æ—Ç—ã (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Ç -180 –¥–æ 180)")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        null_counts = df[self.REQUIRED_COLUMNS['objects']].isnull().sum()
        if null_counts.any():
            for col, count in null_counts[null_counts > 0].items():
                self.warnings.append(f"–ö–æ–ª–æ–Ω–∫–∞ '{col}' —Å–æ–¥–µ—Ä–∂–∏—Ç {count} –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
        
        return len(self.errors) == 0, self.errors, self.warnings
    
    def validate_diagnostics(self, df: pd.DataFrame, objects_df: pd.DataFrame = None) -> Tuple[bool, List[str], List[str]]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫"""
        self.errors = []
        self.warnings = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        missing_cols = set(self.REQUIRED_COLUMNS['diagnostics']) - set(df.columns)
        if missing_cols:
            found_cols = ', '.join(df.columns.tolist())
            self.errors.append(
                f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_cols)}\n"
                f"üìã –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ñ–∞–π–ª–µ: {found_cols}\n"
                f"üí° –°–∫–∞—á–∞–π—Ç–µ —à–∞–±–ª–æ–Ω –∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ (—Ä–µ–≥–∏—Å—Ç—Ä –≤–∞–∂–µ–Ω!)"
            )
            return False, self.errors, self.warnings
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ diag_id
        if df['diag_id'].duplicated().any():
            duplicates = df[df['diag_id'].duplicated()]['diag_id'].tolist()
            self.errors.append(f"–î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è diag_id: {duplicates[:5]}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç–æ–¥–æ–≤ –∫–æ–Ω—Ç—Ä–æ–ª—è
        invalid_methods = df[~df['method'].isin(self.VALID_METHODS)]['method'].unique()
        if len(invalid_methods) > 0:
            self.warnings.append(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã: {list(invalid_methods)}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç
        try:
            pd.to_datetime(df['date'], errors='coerce')
            invalid_dates = df['date'].isna().sum()
            if invalid_dates > 0:
                self.warnings.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞—Ç: {invalid_dates}")
        except Exception:
            self.errors.append("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
        if 'quality_grade' in df.columns:
            invalid_grades = df[~df['quality_grade'].isin(self.VALID_QUALITY_GRADES)]['quality_grade'].unique()
            if len(invalid_grades) > 0:
                self.warnings.append(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞: {list(invalid_grades)}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ ml_label
        if 'ml_label' in df.columns:
            invalid_labels = df[~df['ml_label'].isin(self.VALID_ML_LABELS)]['ml_label'].unique()
            if len(invalid_labels) > 0:
                self.warnings.append(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –º–µ—Ç–∫–∏ ML: {list(invalid_labels)}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤—è–∑–∏ —Å –æ–±—ä–µ–∫—Ç–∞–º–∏
        if objects_df is not None:
            valid_object_ids = set(objects_df['object_id'].values)
            invalid_refs = df[~df['object_id'].isin(valid_object_ids)]['object_id'].unique()
            if len(invalid_refs) > 0:
                self.errors.append(f"–°—Å—ã–ª–∫–∏ –Ω–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ object_id: {list(invalid_refs)[:10]}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–µ—Ñ–µ–∫—Ç–æ–≤
        if 'defect_found' in df.columns:
            defect_rows = df[df['defect_found'] == True]
            if len(defect_rows) > 0:
                if 'param1' in df.columns and defect_rows['param1'].isna().sum() > 0:
                    self.warnings.append(f"–£ –¥–µ—Ñ–µ–∫—Ç–æ–≤ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç param1: {defect_rows['param1'].isna().sum()} –∑–∞–ø–∏—Å–µ–π")
        
        return len(self.errors) == 0, self.errors, self.warnings


class DataImporter:
    """–ò–º–ø–æ—Ä—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV/XLSX"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self.validator = ImportValidator()
        self.import_log = []
    
    def read_file(self, file_content: bytes, filename: str) -> pd.DataFrame:
        """–ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ (CSV –∏–ª–∏ XLSX)"""
        try:
            if filename.endswith('.csv'):
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏ –æ—á–∏—â–∞–µ–º BOM
                for encoding in ['utf-8-sig', 'utf-8', 'cp1251', 'latin1']:
                    try:
                        df = pd.read_csv(io.BytesIO(file_content), encoding=encoding)
                        # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –Ω–µ–≤–∏–¥–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                        df.columns = df.columns.str.strip().str.replace('\ufeff', '').str.replace('\u200b', '')
                        return df
                    except (UnicodeDecodeError, pd.errors.ParserError):
                        continue
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV —Ñ–∞–π–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–¥–∏—Ä–æ–≤–∫—É.")
            elif filename.endswith('.xlsx'):
                df = pd.read_excel(io.BytesIO(file_content))
                # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
                df.columns = df.columns.str.strip().str.replace('\ufeff', '').str.replace('\u200b', '')
                return df
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {filename}")
        except Exception as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
    
    def import_objects(self, file_content: bytes, filename: str) -> Dict:
        """–ò–º–ø–æ—Ä—Ç —Ç–∞–±–ª–∏—Ü—ã –æ–±—ä–µ–∫—Ç–æ–≤"""
        result = {
            'success': False,
            'rows_imported': 0,
            'errors': [],
            'warnings': [],
            'preview': []
        }
        
        try:
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
            df = self.read_file(file_content, filename)
            result['preview'] = df.head(10).to_dict('records')
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            is_valid, errors, warnings = self.validator.validate_objects(df)
            result['errors'] = errors
            result['warnings'] = warnings
            
            if not is_valid:
                self.import_log.append({
                    'timestamp': datetime.now().isoformat(),
                    'file': filename,
                    'status': 'FAILED',
                    'errors': errors
                })
                return result
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ data/
            output_path = os.path.join(self.data_dir, "Objects.csv")
            df.to_csv(output_path, index=False, encoding='utf-8')
            
            result['success'] = True
            result['rows_imported'] = len(df)
            
            self.import_log.append({
                'timestamp': datetime.now().isoformat(),
                'file': filename,
                'status': 'SUCCESS',
                'rows': len(df)
            })
            
        except Exception as e:
            result['errors'].append(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
            self.import_log.append({
                'timestamp': datetime.now().isoformat(),
                'file': filename,
                'status': 'ERROR',
                'error': str(e)
            })
        
        return result
    
    def import_diagnostics(self, file_content: bytes, filename: str) -> Dict:
        """–ò–º–ø–æ—Ä—Ç —Ç–∞–±–ª–∏—Ü—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫"""
        result = {
            'success': False,
            'rows_imported': 0,
            'errors': [],
            'warnings': [],
            'preview': []
        }
        
        try:
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
            df = self.read_file(file_content, filename)
            result['preview'] = df.head(10).to_dict('records')
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–≤—è–∑–µ–π
            objects_path = os.path.join(self.data_dir, "Objects.csv")
            objects_df = None
            if os.path.exists(objects_path):
                objects_df = pd.read_csv(objects_path)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            is_valid, errors, warnings = self.validator.validate_diagnostics(df, objects_df)
            result['errors'] = errors
            result['warnings'] = warnings
            
            if not is_valid:
                self.import_log.append({
                    'timestamp': datetime.now().isoformat(),
                    'file': filename,
                    'status': 'FAILED',
                    'errors': errors
                })
                return result
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ data/
            output_path = os.path.join(self.data_dir, "Diagnostics.csv")
            df.to_csv(output_path, index=False, encoding='utf-8')
            
            result['success'] = True
            result['rows_imported'] = len(df)
            
            self.import_log.append({
                'timestamp': datetime.now().isoformat(),
                'file': filename,
                'status': 'SUCCESS',
                'rows': len(df)
            })
            
        except Exception as e:
            result['errors'].append(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
            self.import_log.append({
                'timestamp': datetime.now().isoformat(),
                'file': filename,
                'status': 'ERROR',
                'error': str(e)
            })
        
        return result
    
    def get_import_log(self) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∏–º–ø–æ—Ä—Ç–∞"""
        return self.import_log
